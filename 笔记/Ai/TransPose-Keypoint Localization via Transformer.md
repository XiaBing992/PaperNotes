# 摘要
CNN在关键点检测方面取得了很好的效果，但是其不能很好的解决空间依赖关系。在本文中，采用了transformer结构用于人类姿态检测。在COCO验证和测试开发集上，TransPose获得了75.8 AP和75.0 AP。
# 介绍
现在姿态检测要弄清楚空间依赖关系有以下几点挑战：
1. 深度：基于CNN的模型，通常有很深的非线性单元，阻止了每一层的解释
2. 隐含关系：身体部位之间的关系隐含在全局的神经元激活和权重中

本文目标是构建一个姿态检测器能够清楚的捕获和揭示关键点之间的空间依赖关系
- 提出了TransPose，使用卷积提取low-level特征，使用Transformer提取high-level特征
- 在Transformer的输入上，展平了特征图。并将输出的结构恢复到二维特征图'

贡献：
1. 提出了一种用于姿态检测的Transformer架构，这种架构可以很好的捕获空间关系
2. 这种结构有着很好的表现，和使用CNN的相比，有着更少的参数和更快的速度


结构：
Backbone + Transformer + Head
- Backbone: 使用CNN架构，为了更好的做对比，用了两种架构---ResNet 和 HRNet. 
- Transformer: 使用了标准的Transformer架构的encoder架构，因为认为热力图输出任务只是一个编码任务
- Head：用于预测K个热力图，H = H/4 , W = W/4 

实验：
- 数据集：验证集使用COCO和MPII
- 技术细节：训练样本是单人的256*192，使用了数据增强，Adam优化器，sine位置编码
- 对比不同的位置编码
- 不同输入大小的图片
- Transformer层数的对比
  