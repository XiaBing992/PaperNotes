# ViTPose-Simple Vision Transformer Baselines for Human Pose Estimation

## 摘要
transformer在视觉领域中有着很好的表现，但是在姿态识别任务方面，几乎没有研究来揭示其潜力。本文中，我们展示了其惊人的能力，即模型结构的简单、灵活，将其命名位VITPose。Vitpose使用了一种普通的transformer作为backbone去提取人的特征，并且使用了一种轻量级的解码器作为姿态的检验。此外，ViTPose在注意类型、输入分辨率、预训练和微调策略以及处理多个姿势任务方面都非常灵活。

## 介绍
- 目前的大多数模型都是使用CNN作为backbone，这引发我们思考，直接使用transformer作为姿态检测会怎么样？   
- VITPose = Transformer + 轻量级decoder
- 80.9 AP on coco
- 本文不重点关注算法的优越性，而是关注其简单以及高的性能

### 优点
1. 不需要特别领域的知识去设计encoder，只需要简单堆叠transformer的层数
2. 可伸缩性强，通过层数改变模型结构
3. 在训练阶段非常灵活，可以使用不同的输入维度的方案，越高的维度的图片越精确
4. 即使预训练阶段使用少的数据集，也能表现得很好

### 贡献
1. 提出了一个简单但很好得模型VITPose
2. 有着很好的能力，包括结构简单性，训练灵活性，知识可迁移性

### VITPose

#### 结构简单性
- 本文尽可能保持模型的简单性，使用了几个decoder进行测试
- 没有使用跳层或者cross attention在decoder中

#### 灵活性
- 预训练数据灵活性：imageNet作为backbone的预训练是非常好的。然而，这需要额外的数据，使得姿态检测对于数据的要求更高。为了探索数据的灵活性，除了使用imagenet之外，本文使用MAE作为预训练。最后的结果显示尽管这种数据量小于imagenet，也能获得很好的性能，这意味着vitpose在预训练方面有着很好的灵活性
- 分辨率灵活性：本文使用不同的输入尺寸以及下采样率去评测分辨率的灵活性。最后发现更高的分辨率有着更高的准确率
- attention 类型的灵活性：在高分辨率的输入上，可以使用其他attention来减小复杂度
- 微调的灵活性：将模型微调到其他数据集有着很好的效果

#### 可迁移性
模型蒸馏

## 实验

### 实现细节
- 使用了top-down用于姿态检测

### 消融实验

### 主观结果
- 在复杂的场景中，模型也能有好的结果

## 讨论

